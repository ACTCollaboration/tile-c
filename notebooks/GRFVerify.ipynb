{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from orphics import maps,io,cosmology,stats\n",
    "from pixell import enmap\n",
    "import numpy as np\n",
    "from szar import foregrounds as fg\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msyriac/repos/szar/szar/foregrounds.py:80: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  noise = fgfunc(self.ells,self.nu0,self.nu0)*2.*np.pi*np.nan_to_num(1./self.ells/(self.ells+1.))\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/msyriac/repos/orphics/orphics/cosmology.py:1171: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  atmFactor = (lknee*np.nan_to_num(1./ell))**(-alpha)\n",
      "/home/msyriac/repos/orphics/orphics/cosmology.py:1171: RuntimeWarning: overflow encountered in multiply\n",
      "  atmFactor = (lknee*np.nan_to_num(1./ell))**(-alpha)\n"
     ]
    }
   ],
   "source": [
    "class ArrayGen(object):\n",
    "      def __init__(self,shape,wcs,theory,freqs,beams,noises,lknees,alphas,ellmins,ellmaxes):\n",
    "\n",
    "          fgn = fg.fgNoises(cosmology.defaultConstants,ksz_file='/home/msyriac/repos/szar/input/ksz_BBPS.txt',\n",
    "                    ksz_p_file='/home/msyriac/repos/szar/input/ksz_p_BBPS.txt',\n",
    "                    tsz_cib_file='/home/msyriac/repos/szar/input/sz_x_cib_template.txt',\n",
    "                    ksz_battaglia_test_csv=None,\n",
    "                    tsz_battaglia_template_csv=\"/home/msyriac/repos/szar/input/sz_template_battaglia.csv\",\n",
    "                    rs_template=\"/home/msyriac/repos/szar/input/fiducial_scalCls_lensed_5_5.txt\",\n",
    "                    rsx_template=\"/home/msyriac/repos/szar/input/fiducial_scalCls_lensed_1_5.txt\",\n",
    "                    components=['tsz','cibp','cibc','radps'],lmax=20000)\n",
    "        \n",
    "          self.modlmap = enmap.modlmap(shape,wcs)\n",
    "          modlmap = self.modlmap\n",
    "          self.fgn = fgn\n",
    "          lmax = self.modlmap.max()\n",
    "          ells = np.arange(0,lmax,1)\n",
    "          ps_cmb = theory.lCl('TT',modlmap).reshape((1,1,shape[-2],shape[-1]))\n",
    "          self.ps_cmb = ps_cmb\n",
    "          ps_y = fgn.tsz_template(ells).reshape((1,1,ells.size))*self.fgn.c['A_tsz']*2.*np.pi*np.nan_to_num(1./ells/(ells+1.))\n",
    "          ps_cibp = (fgn.c['A_cibp'] * ((ells/fgn.c['ell0sec'])) ** 2.0 *2.*np.pi*np.nan_to_num(1./ells/(ells+1.))).reshape((1,1,ells.size))\n",
    "          ps_cibc = (fgn.c['A_cibc'] * ((ells/fgn.c['ell0sec'])) ** (2.-fgn.c['n_cib']) * \\\n",
    "                  2.*np.pi*np.nan_to_num(1./ells/(ells+1.))).reshape((1,1,ells.size))\n",
    "          ps_radps = (fgn.c['A_ps'] * ((ells/fgn.c['ell0sec'])) ** 2 * \\\n",
    "                  2.*np.pi*np.nan_to_num(1./ells/(ells+1.))).reshape((1,1,ells.size))\n",
    "          self.cgen = maps.MapGen(shape[-2:],wcs,ps_cmb)\n",
    "          self.tgen = maps.MapGen(shape[-2:],wcs,ps_y)\n",
    "          self.cibpgen = maps.MapGen(shape[-2:],wcs,ps_cibp)\n",
    "          self.cibcgen = maps.MapGen(shape[-2:],wcs,ps_cibc)\n",
    "          self.radpsgen = maps.MapGen(shape[-2:],wcs,ps_radps)\n",
    "          self.shape = shape ; self.wcs = wcs\n",
    "          self.freqs = freqs\n",
    "          self.kbeams = []\n",
    "          self.ngens = []\n",
    "          self.n2ds = []\n",
    "          for ai,nu in enumerate(self.freqs):\n",
    "              self.kbeams.append(maps.gauss_beam(fwhm=beams[ai],ell=self.modlmap))\n",
    "              n2d = cosmology.noise_func(self.modlmap,0,noises[ai],lknee=lknees[ai],alpha=alphas[ai],dimensionless=False,TCMB=2.7255e6)\n",
    "              n2d[modlmap<ellmins[ai]] = 0\n",
    "              n2d[modlmap>ellmaxes[ai]] = 0\n",
    "              n2dmod = n2d.copy()\n",
    "              n2dmod[modlmap>ellmaxes[ai]] =  1e90\n",
    "              n2dmod[modlmap<ellmins[ai]] =  1e90\n",
    "              self.n2ds.append(n2dmod.copy())\n",
    "              ps_noise = n2d.reshape((1,1,shape[-2],shape[-1]))\n",
    "              self.ngens.append(maps.MapGen(shape[-2:],wcs,ps_noise))\n",
    "          self.ellmins = ellmins\n",
    "          self.ellmaxes = ellmaxes\n",
    "          \n",
    "      def get_maps(self,seed=None):\n",
    "          cmb = self.cgen.get_map(seed=(1,seed) if seed is not None else None)\n",
    "          y = self.tgen.get_map(seed=(2,seed) if seed is not None else None)\n",
    "          cibp = self.cibpgen.get_map(seed=(4,seed) if seed is not None else None)\n",
    "          cibc = self.cibcgen.get_map(seed=(5,seed) if seed is not None else None)\n",
    "          radps = self.radpsgen.get_map(seed=(6,seed) if seed is not None else None)\n",
    "          observed = []\n",
    "          for ai,nu in enumerate(self.freqs):\n",
    "              tsz = self.fgn.tSZ_nu(nu) * y\n",
    "              tsz += (self.fgn.cib_nu(nu) * cibp + self.fgn.cib_nu(nu) * cibc + self.fgn.rad_ps_nu(nu) * radps )\n",
    "              observed.append(self._filter(self._beam(cmb+tsz,ai)+self._noise(ai,seed),ai))\n",
    "          observed = np.stack(observed)\n",
    "          return cmb,y,observed\n",
    "      def _beam(self,imap,ai):\n",
    "          return maps.filter_map(imap,self.kbeams[ai])\n",
    "      def _noise(self,ai,seed=None):\n",
    "          return self.ngens[ai].get_map(seed=(3,seed) if seed is not None else None)\n",
    "      def _filter(self,imap,ai):\n",
    "          kmask = maps.mask_kspace(self.shape,self.wcs,lmin=self.ellmins[ai],lmax=self.ellmaxes[ai])\n",
    "          return maps.filter_map(imap,kmask)\n",
    "      \n",
    "      def get_cov(self):\n",
    "          pass\n",
    "\n",
    "deg = 5.\n",
    "px = 1.0\n",
    "shape,wcs = maps.rect_geometry(width_deg=deg,px_res_arcmin=px)\n",
    "theory = cosmology.default_theory()\n",
    "\n",
    "# ACT + Planck III\n",
    "#freqs = [150,150,150,150,150,90,143,217,353]\n",
    "#beams = np.array([1.5,1.5,1.5,1.5,1.5,2.3,7.,5.,5.])\n",
    "#noises = [20.,20.,20.,20.,15.,20.,43.,66.,200.]\n",
    "#lknees = [3000.]*5 + [1000.] + [0.]*3\n",
    "#alphas = [-4.]*6 + [1.]*3\n",
    "#ellmins = [300]*6 + [2]*3\n",
    "#ellmaxes = [6000]*6 + [6000]*3\n",
    "\n",
    "\n",
    "# ACT + Planck I\n",
    "#freqs = [150,150,150,150,150,90,70,100,143,217,353]\n",
    "#beams = np.array([1.5,1.5,1.5,1.5,1.5,2.3,14.,10.,7.,5.,5.])\n",
    "#noises = [20.,20.,20.,20.,15.,20.,137.,65.,43.,66.,200.]\n",
    "#lknees = [3000.]*5 + [1000.] + [0.]*5\n",
    "#alphas = [-4.]*6 + [1.]*5\n",
    "#ellmins = [300]*6 + [2]*5\n",
    "#ellmaxes = [2000]*6 + [2000]*5\n",
    "\n",
    "\n",
    "# ACT + Planck II\n",
    "freqs = [150,150,150,150,150,90,100,143,217,353]\n",
    "beams = np.array([1.5,1.5,1.5,1.5,1.5,2.3,10.,7.,5.,5.])\n",
    "noises = [20.,20.,20.,20.,15.,20.,65.,43.,66.,200.]\n",
    "lknees = [3000.]*5 + [1000.] + [0.]*4\n",
    "alphas = [-4.]*6 + [1.]*4\n",
    "ellmins = [300]*6 + [2]*4\n",
    "ellmaxes = [3500]*6 + [3500]*4\n",
    "\n",
    "# ACT\n",
    "#freqs = [150,150,150,150,150,90]\n",
    "#beams = np.array([1.5,1.5,1.5,1.5,1.5,2.3])\n",
    "#noises = [20.,20.,20.,20.,15.,20.]\n",
    "#lknees = [3000.]*5 + [1000.]\n",
    "#alphas = [-4.]*6 \n",
    "#ellmins = [300]*6 \n",
    "#ellmaxes = [6000]*6 \n",
    "\n",
    "# Planck\n",
    "#freqs = [70,100,143,217,353]\n",
    "#beams = np.array([14.,10.,7.,5.,5.])\n",
    "#noises = [137.,65.,43.,66.,200.]\n",
    "#lknees = [0.]*5\n",
    "#alphas = [1.]*5\n",
    "#ellmins = [2]*5\n",
    "#ellmaxes = [3000]*5\n",
    "\n",
    "\n",
    "\n",
    "assert len(freqs)==len(beams)==len(noises)==len(lknees)==len(alphas)\n",
    "pnum = 0\n",
    "agen = ArrayGen(shape,wcs,theory,freqs[pnum:],beams[pnum:],noises[pnum:],lknees[pnum:],alphas[pnum:],ellmins[pnum:],ellmaxes[pnum:])\n",
    "cmb,y,observed = agen.get_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 90\n",
      "Populating covariance for  150 x 100\n",
      "Populating covariance for  150 x 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 353\n",
      "Populating covariance for  150 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 90\n",
      "Populating covariance for  150 x 100\n",
      "Populating covariance for  150 x 143\n",
      "Populating covariance for  150 x 217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 90\n",
      "Populating covariance for  150 x 100\n",
      "Populating covariance for  150 x 143\n",
      "Populating covariance for  150 x 217\n",
      "Populating covariance for  150 x 353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 90\n",
      "Populating covariance for  150 x 100\n",
      "Populating covariance for  150 x 143\n",
      "Populating covariance for  150 x 217\n",
      "Populating covariance for  150 x 353\n",
      "Populating covariance for  150 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  150 x 150\n",
      "Populating covariance for  150 x 90\n",
      "Populating covariance for  150 x 100\n",
      "Populating covariance for  150 x 143\n",
      "Populating covariance for  150 x 217\n",
      "Populating covariance for  150 x 353\n",
      "Populating covariance for  90 x 150\n",
      "Populating covariance for  90 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  90 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  90 x 150\n",
      "Populating covariance for  90 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  90 x 90\n",
      "Populating covariance for  90 x 100\n",
      "Populating covariance for  90 x 143\n",
      "Populating covariance for  90 x 217\n",
      "Populating covariance for  90 x 353\n",
      "Populating covariance for  100 x 150\n",
      "Populating covariance for  100 x 150\n",
      "Populating covariance for  100 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  100 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  100 x 150\n",
      "Populating covariance for  100 x 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  100 x 100\n",
      "Populating covariance for  100 x 143\n",
      "Populating covariance for  100 x 217\n",
      "Populating covariance for  100 x 353\n",
      "Populating covariance for  143 x 150\n",
      "Populating covariance for  143 x 150\n",
      "Populating covariance for  143 x 150\n",
      "Populating covariance for  143 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  143 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  143 x 90\n",
      "Populating covariance for  143 x 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  143 x 143\n",
      "Populating covariance for  143 x 217\n",
      "Populating covariance for  143 x 353\n",
      "Populating covariance for  217 x 150\n",
      "Populating covariance for  217 x 150\n",
      "Populating covariance for  217 x 150\n",
      "Populating covariance for  217 x 150\n",
      "Populating covariance for  217 x 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  217 x 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  217 x 100\n",
      "Populating covariance for  217 x 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  217 x 217\n",
      "Populating covariance for  217 x 353\n",
      "Populating covariance for  353 x 150\n",
      "Populating covariance for  353 x 150\n",
      "Populating covariance for  353 x 150\n",
      "Populating covariance for  353 x 150\n",
      "Populating covariance for  353 x 150\n",
      "Populating covariance for  353 x 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  353 x 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  353 x 143\n",
      "Populating covariance for  353 x 217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating covariance for  353 x 353\n",
      "Inverting covariance...\n"
     ]
    }
   ],
   "source": [
    "cinv,cov  = maps.ilc_cinv(agen.modlmap,agen.ps_cmb[0,0],agen.kbeams,agen.freqs,agen.n2ds,['tsz','cibp','cibc','radps'],agen.fgn,plot=False,plot_save=None,ellmaxes=ellmaxes,eigpow=True)\n",
    "\n",
    "for ai in range(len(freqs)):\n",
    "    for aj in range(len(freqs)):\n",
    "        cinv[ai,aj][agen.modlmap<ellmins[ai]] = 0\n",
    "        cinv[ai,aj][agen.modlmap<ellmins[aj]] = 0\n",
    "        cinv[ai,aj][agen.modlmap>ellmaxes[ai]] = 0\n",
    "        cinv[ai,aj][agen.modlmap>ellmaxes[aj]] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 300, 300)\n"
     ]
    }
   ],
   "source": [
    "print(cinv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msyriac/repos/orphics/orphics/maps.py:810: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.nan_to_num(1./ilc_comb_a_b(response,response,cinv))\n",
      "/home/msyriac/repos/orphics/orphics/maps.py:786: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.nan_to_num(numer/norm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msyriac/repos/orphics/orphics/stats.py:859: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret['corr'] = ret['cov'] / stddev[:, None]\n",
      "/home/msyriac/repos/orphics/orphics/stats.py:860: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret['corr'] = ret['cov'] / stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Set up SZ frequency dependence\n",
    "def gnu(nu_ghz,tcmb=2.7255):\n",
    "    nu = 1e9*np.asarray(nu_ghz)\n",
    "    hplanck = 6.62607e-34\n",
    "    kboltzmann = 1.38065e-23 \n",
    "    x = hplanck*nu/kboltzmann/tcmb\n",
    "    coth = np.cosh(x/2.)/np.sinh(x/2.)\n",
    "    return x*coth-4.\n",
    "\n",
    "yresponses = gnu(freqs)\n",
    "cresponses = yresponses*0 + 1.\n",
    "nsims = 5\n",
    "fc = maps.FourierCalc(shape[-2:],wcs)\n",
    "s = stats.Stats()\n",
    "bin_edges = np.arange(300,5000,80)\n",
    "binner = stats.bin2D(agen.modlmap,bin_edges)\n",
    "\n",
    "for i in range(nsims):\n",
    "    cmb,y,observed = agen.get_maps()\n",
    "    kmaps = []\n",
    "    for j in range(len(freqs)):\n",
    "        _,kmap,_ = fc.power2d(observed[j])\n",
    "        km = np.nan_to_num(kmap/agen.kbeams[j])\n",
    "        km[agen.modlmap>ellmaxes[j]] = 0\n",
    "        km[agen.modlmap<ellmins[j]] = 0\n",
    "        kmaps.append(km.copy()) \n",
    "    kmaps = np.stack(kmaps)\n",
    "    sc = maps.silc(kmaps,cinv,cresponses)\n",
    "    sy = maps.silc(kmaps,cinv,yresponses)\n",
    "    cc = maps.cilc(kmaps,cinv,cresponses,yresponses)\n",
    "    cy = maps.cilc(kmaps,cinv,yresponses,cresponses)\n",
    "\n",
    "    pcmb,kcmb,_ = fc.power2d(cmb,cmb)\n",
    "    py,ky,_ = fc.power2d(y,y)\n",
    "    psc_cmb = fc.f2power(sc,kcmb)\n",
    "    pcc_cmb = fc.f2power(cc,kcmb)\n",
    "    psy_y = fc.f2power(sy,ky)\n",
    "    pcy_y = fc.f2power(cy,ky)\n",
    "    psc = fc.f2power(sc,sc)\n",
    "    pcc = fc.f2power(cc,cc)\n",
    "    psy = fc.f2power(sy,sy)\n",
    "    pcy = fc.f2power(cy,cy)\n",
    "\n",
    "    cents,cl_cmb = binner.bin(pcmb)\n",
    "    cents,cl_y = binner.bin(py)\n",
    "    cents,cl_sc_cmb = binner.bin(psc_cmb)\n",
    "    cents,cl_cc_cmb = binner.bin(pcc_cmb)\n",
    "    cents,cl_sy_y = binner.bin(psy_y)\n",
    "    cents,cl_cy_y = binner.bin(pcy_y)\n",
    "    cents,cl_sc = binner.bin(psc)\n",
    "    cents,cl_cc = binner.bin(pcc)\n",
    "    cents,cl_sy = binner.bin(psy)\n",
    "    cents,cl_cy = binner.bin(pcy)\n",
    "    \n",
    "    s.add_to_stats(\"cmb\",cl_cmb)\n",
    "    s.add_to_stats(\"y\",cl_y)\n",
    "    s.add_to_stats(\"scxcmb\",cl_sc_cmb)\n",
    "    s.add_to_stats(\"ccxcmb\",cl_cc_cmb)\n",
    "    s.add_to_stats(\"syxy\",cl_sy_y)\n",
    "    s.add_to_stats(\"cyxy\",cl_cy_y)\n",
    "    s.add_to_stats(\"sc\",cl_sc)\n",
    "    s.add_to_stats(\"cc\",cl_cc)\n",
    "    s.add_to_stats(\"sy\",cl_sy)\n",
    "    s.add_to_stats(\"cy\",cl_cy)\n",
    "\n",
    "    print(i)\n",
    "s.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8333638104020403e-05 1e+30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msyriac/repos/orphics/orphics/maps.py:810: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.nan_to_num(1./ilc_comb_a_b(response,response,cinv))\n",
      "/home/msyriac/repos/orphics/orphics/maps.py:822: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.nan_to_num(numer/denom)\n"
     ]
    }
   ],
   "source": [
    "cmb = s.stats['cmb']['mean']\n",
    "y = s.stats['y']['mean']\n",
    "scxcmb = s.stats['scxcmb']['mean']\n",
    "ccxcmb = s.stats['ccxcmb']['mean']\n",
    "syxy = -s.stats['syxy']['mean']\n",
    "cyxy = -s.stats['cyxy']['mean']\n",
    "escxcmb = s.stats['scxcmb']['err']\n",
    "eccxcmb = s.stats['ccxcmb']['err']\n",
    "esyxy = s.stats['syxy']['err']\n",
    "ecyxy = s.stats['cyxy']['err']\n",
    "sc = s.stats['sc']['mean']\n",
    "cc = s.stats['cc']['mean']\n",
    "sy = s.stats['sy']['mean']\n",
    "cy = s.stats['cy']['mean']\n",
    "\n",
    "sc_noise = binner.bin(maps.silc_noise(cinv,cresponses))[1]\n",
    "sy_noise = binner.bin(maps.silc_noise(cinv,yresponses))[1]\n",
    "cc_noise = binner.bin(maps.cilc_noise(cinv,cresponses,yresponses))[1]\n",
    "cy_noise = binner.bin(maps.cilc_noise(cinv,yresponses,cresponses))[1]\n",
    "sn = maps.silc_noise(cinv,cresponses)\n",
    "sn[sn<-1e30] = -1e30\n",
    "sn[sn>1e30] = 1e30\n",
    "print(sn.min(),sn.max())\n",
    "io.plot_img(np.log10(np.fft.fftshift(sn)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSaved plot to IIcmb.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tt = binner.bin(agen.ps_cmb)[1]\n",
    "\n",
    "lss,snls = np.loadtxt(\"/home/msyriac/repos/halofg/data/smica_nls.txt\",unpack=True)\n",
    "lsl,lnls = np.loadtxt(\"/home/msyriac/repos/halofg/data/lgmca_nls.txt\",unpack=True)\n",
    "snls = snls[lss<3000]\n",
    "lss = lss[lss<3000]\n",
    "lnls = lnls[lsl<3000]\n",
    "lsl = lsl[lsl<3000]\n",
    "\n",
    "\n",
    "pl = io.Plotter(yscale='log',xlabel='l',ylabel='D')\n",
    "pl.add(cents,cmb*cents**2.,lw=2,color='k')\n",
    "pl.add_err(cents,scxcmb*cents**2.,yerr=escxcmb*cents**2,lw=1,label=\"ilc\",marker=\"o\",color=\"C0\")\n",
    "pl.add_err(cents,ccxcmb*cents**2.,yerr=eccxcmb*cents**2,lw=1,label=\"cilc\",marker=\"o\",color=\"C1\")\n",
    "pl.add(cents,sc*cents**2.,lw=1,ls=\"--\",color=\"C0\")\n",
    "pl.add(cents,cc*cents**2.,lw=1,ls=\"--\",color=\"C1\")\n",
    "pl.add(cents,(sc_noise-tt)*cents**2.,lw=1,ls=\"-.\",color=\"C0\")\n",
    "pl.add(cents,(cc_noise-tt)*cents**2.,lw=1,ls=\"-.\",color=\"C1\")\n",
    "pl.add(lss,(snls)*lss**2./maps.gauss_beam(lss,5.)**2.,lw=1,ls=\"-.\",color=\"C2\",label='smica',alpha=0.5)\n",
    "pl.add(lsl,(lnls)*lsl**2./maps.gauss_beam(lss,5.)**2.,lw=1,ls=\"-.\",color=\"C3\",label='lgmca',alpha=0.5)\n",
    "pl._ax.set_ylim(1e1,3e4)\n",
    "pl.legend(loc='lower center')\n",
    "pl.done(\"IIcmb.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSaved plot to IIy.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pl = io.Plotter(yscale='log',xlabel='l',ylabel='D')\n",
    "#pl = io.Plotter(xlabel='l',ylabel='D')\n",
    "pl.add(cents,y*cents**2.,lw=2,color='k')\n",
    "pl.add_err(cents,syxy*cents**2.,yerr=esyxy*cents**2,lw=1,label=\"ilc\",marker=\"o\",color=\"C0\")\n",
    "pl.add_err(cents,cyxy*cents**2.,yerr=ecyxy*cents**2,lw=1,label=\"cilc\",marker=\"o\",color=\"C1\")\n",
    "pl.add(cents,sy*cents**2.,lw=1,ls=\"--\",color=\"C0\")\n",
    "pl.add(cents,cy*cents**2.,lw=1,ls=\"--\",color=\"C1\")\n",
    "pl.add(cents,sy_noise*cents**2.,lw=1,ls=\"-.\",color=\"C0\")\n",
    "pl.add(cents,cy_noise*cents**2.,lw=1,ls=\"-.\",color=\"C1\")\n",
    "#pl.hline()\n",
    "pl._ax.set_ylim(2e0,2e4)\n",
    "pl.done(\"IIy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0 to 2000 : ACT + 70,100,143,217,353\\n2000 to 3500 : ACT + 100,143,217,353\\n3500 to 6000 : ACT + 143,217,353\\n6000 to 20000 : ACT\\n'"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "P 0 to 2000 : 70,100,143,217,353\n",
    "I 0 to 2000 : ACT + 70,100,143,217,353\n",
    "II 2000 to 3500 : ACT + 100,143,217,353\n",
    "III 3500 to 6000 : ACT + 143,217,353\n",
    "IV 6000 to 20000 : ACT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": "GRFVerify.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
